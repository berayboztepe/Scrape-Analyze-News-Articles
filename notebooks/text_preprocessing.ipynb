{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\beray\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\beray\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Apple and SpaceX Link Up to Support Starlink S...   \n",
      "1  Compile Heart and M2 shoot ’em up titled Zales...   \n",
      "2  Legendary 'Father of Final Fantasy' Returns to...   \n",
      "3  Steam-Heart’s & Advanced Variable Geo Saturn T...   \n",
      "4  DOOM + DOOM II Switch Update 2 Now Live, Here ...   \n",
      "\n",
      "                                       cleaned_title  \n",
      "0  apple spacex link support starlink satellite n...  \n",
      "1  compile heart m2 shoot ’ em titled zaleste gem...  \n",
      "2  legendary father final fantasy returns make on...  \n",
      "3  steamheart ’ advanced variable geo saturn trib...  \n",
      "4  doom doom ii switch update 2 live full patch n...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"../data\", \"news.csv\"))\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"cleaned_title\"] = df[\"title\"].dropna().apply(preprocess_text)\n",
    "print(df[[\"title\", \"cleaned_title\"]].head())\n",
    "\n",
    "df.to_csv(os.path.join(\"../data\", \"news_cleaned.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
